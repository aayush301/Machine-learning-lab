{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from ANN import ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.6931471805599453\n",
      "Epoch: 1, loss: 21.02690343162694\n",
      "Epoch: 2, loss: 13.51218577282786\n",
      "Epoch: 3, loss: 21.02690343162694\n",
      "Epoch: 4, loss: 13.51218577282786\n",
      "Epoch: 5, loss: 21.02690343162694\n",
      "Epoch: 6, loss: 21.02690343162694\n",
      "Epoch: 7, loss: 13.51218577282786\n",
      "Epoch: 8, loss: 21.02690343162694\n",
      "Epoch: 9, loss: 13.436274616800736\n",
      "Epoch: 10, loss: 21.02690343162694\n",
      "Epoch: 11, loss: 21.02690343162694\n",
      "Epoch: 12, loss: 13.51218577282786\n",
      "Epoch: 13, loss: 21.02690343162694\n",
      "Epoch: 14, loss: 11.310762248041298\n",
      "Epoch: 15, loss: 21.02690343162694\n",
      "Epoch: 16, loss: 20.875084634286676\n",
      "Epoch: 17, loss: 13.51218577282786\n",
      "Epoch: 18, loss: 21.02690343162694\n",
      "Epoch: 19, loss: 13.51218577282786\n",
      "Epoch: 20, loss: 21.02690343162694\n",
      "Epoch: 21, loss: 21.02690343162694\n",
      "Epoch: 22, loss: 13.51218577282786\n",
      "Epoch: 23, loss: 21.02690343162694\n",
      "Epoch: 24, loss: 13.284452304746491\n",
      "Epoch: 25, loss: 21.02690343162694\n",
      "Epoch: 26, loss: 20.950994032956807\n",
      "Epoch: 27, loss: 13.51218577282786\n",
      "Epoch: 28, loss: 21.02690343162694\n",
      "Epoch: 29, loss: 12.828985368583755\n",
      "Epoch: 30, loss: 21.02690343162694\n",
      "Epoch: 31, loss: 18.370076235529268\n",
      "Epoch: 32, loss: 13.51218577282786\n",
      "Epoch: 33, loss: 21.02690343162694\n",
      "Epoch: 34, loss: 11.842140340231156\n",
      "Epoch: 35, loss: 21.02690343162694\n",
      "Epoch: 36, loss: 4.858231389957357\n",
      "Epoch: 37, loss: 4.402838262788177\n",
      "Epoch: 38, loss: 21.02690343162694\n",
      "Epoch: 39, loss: 13.51218577282786\n",
      "Epoch: 40, loss: 21.02690343162694\n",
      "Epoch: 41, loss: 8.957516411200492\n",
      "Epoch: 42, loss: 21.02690343162694\n",
      "Epoch: 43, loss: 11.90943624856294\n",
      "Epoch: 44, loss: 21.02690343162694\n",
      "Epoch: 45, loss: 3.7955191395023724\n",
      "Epoch: 46, loss: 9.944143527286398\n",
      "Epoch: 47, loss: 12.828985368583755\n",
      "Epoch: 48, loss: 21.02690343162694\n",
      "Epoch: 49, loss: 5.769142416641968\n",
      "Epoch: 50, loss: 5.541510875265987\n",
      "Epoch: 51, loss: 21.02690343162694\n",
      "Epoch: 52, loss: 13.436274616800736\n",
      "Epoch: 53, loss: 21.02690343162694\n",
      "Epoch: 54, loss: 5.313777407184618\n",
      "Epoch: 55, loss: 21.02690343162694\n",
      "Epoch: 56, loss: 13.436274616800736\n",
      "Epoch: 57, loss: 21.02690343162694\n",
      "Epoch: 58, loss: 5.7692443433473555\n",
      "Epoch: 59, loss: 21.00304323777194\n",
      "Epoch: 60, loss: 13.360363460773614\n",
      "Epoch: 61, loss: 21.02690343162694\n",
      "Epoch: 62, loss: 5.284721412233578\n",
      "Epoch: 63, loss: 20.875084634286676\n",
      "Epoch: 64, loss: 13.284452304746491\n",
      "Epoch: 65, loss: 21.02690343162694\n",
      "Epoch: 66, loss: 6.376535348921327\n",
      "Epoch: 67, loss: 21.02690343162694\n",
      "Epoch: 68, loss: 13.132629992692246\n",
      "Epoch: 69, loss: 21.02690343162694\n",
      "Epoch: 70, loss: 4.934221627049005\n",
      "Epoch: 71, loss: 20.19190004625548\n",
      "Epoch: 72, loss: 13.132629992692246\n",
      "Epoch: 73, loss: 21.02690343162694\n",
      "Epoch: 74, loss: 6.528357660975573\n",
      "Epoch: 75, loss: 20.875084634286676\n",
      "Epoch: 76, loss: 12.980807680638\n",
      "Epoch: 77, loss: 21.02690343162694\n",
      "Epoch: 78, loss: 5.389688563211741\n",
      "Epoch: 79, loss: 19.736443654234677\n",
      "Epoch: 80, loss: 13.056718836665123\n",
      "Epoch: 81, loss: 21.02690343162694\n",
      "Epoch: 82, loss: 6.3006241928942055\n",
      "Epoch: 83, loss: 20.647356438276276\n",
      "Epoch: 84, loss: 12.828985368583755\n",
      "Epoch: 85, loss: 21.02690343162694\n",
      "Epoch: 86, loss: 6.14880188083996\n",
      "Epoch: 87, loss: 19.964171850245076\n",
      "Epoch: 88, loss: 12.828985368583755\n",
      "Epoch: 89, loss: 21.02690343162694\n",
      "Epoch: 90, loss: 5.845157256731468\n",
      "Epoch: 91, loss: 19.053260823560468\n",
      "Epoch: 92, loss: 12.753074212556633\n",
      "Epoch: 93, loss: 21.02690343162694\n",
      "Epoch: 94, loss: 6.078277853653061\n",
      "Epoch: 95, loss: 19.584626614251402\n",
      "Epoch: 96, loss: 12.601251900502385\n",
      "Epoch: 97, loss: 21.02690343162694\n",
      "Epoch: 98, loss: 6.3006241928942055\n",
      "Epoch: 99, loss: 19.432807816911133\n",
      "Epoch: 100, loss: 12.297607276393894\n",
      "Epoch: 101, loss: 21.02690343162694\n",
      "Epoch: 102, loss: 6.832002285084064\n",
      "Epoch: 103, loss: 19.57006130229117\n",
      "Epoch: 104, loss: 12.145784964339649\n",
      "Epoch: 105, loss: 21.02690343162694\n",
      "Epoch: 106, loss: 6.907913441111186\n",
      "Epoch: 107, loss: 18.977351424890333\n",
      "Epoch: 108, loss: 11.91805149625828\n",
      "Epoch: 109, loss: 21.02690343162694\n",
      "Epoch: 110, loss: 7.211558065219679\n",
      "Epoch: 111, loss: 19.432807816911133\n",
      "Epoch: 112, loss: 11.690318028176913\n",
      "Epoch: 113, loss: 21.02690343162694\n",
      "Epoch: 114, loss: 7.3633803772739235\n",
      "Epoch: 115, loss: 18.977351424890333\n",
      "Epoch: 116, loss: 11.234851092014175\n",
      "Epoch: 117, loss: 20.950994032956807\n",
      "Epoch: 118, loss: 7.970671382847895\n",
      "Epoch: 119, loss: 19.508715458224277\n",
      "Epoch: 120, loss: 11.007117623932807\n",
      "Epoch: 121, loss: 20.950994032956807\n",
      "Epoch: 122, loss: 7.894760226820772\n",
      "Epoch: 123, loss: 18.977351424890333\n",
      "Epoch: 124, loss: 10.931206467905685\n",
      "Epoch: 125, loss: 20.875084634286676\n",
      "Epoch: 126, loss: 7.742937914766526\n",
      "Epoch: 127, loss: 18.294166836859134\n",
      "Epoch: 128, loss: 10.779384155851437\n",
      "Epoch: 129, loss: 20.875084634286676\n",
      "Epoch: 130, loss: 7.894760226820772\n",
      "Epoch: 131, loss: 18.294166836859134\n",
      "Epoch: 132, loss: 10.399828375715822\n",
      "Epoch: 133, loss: 20.647356438276276\n",
      "Epoch: 134, loss: 8.426138319010633\n",
      "Epoch: 135, loss: 18.445985634199403\n",
      "Epoch: 136, loss: 9.792539127498841\n",
      "Epoch: 137, loss: 19.964171850245076\n",
      "Epoch: 138, loss: 8.95751641120049\n",
      "Epoch: 139, loss: 18.52189503286953\n",
      "Epoch: 140, loss: 9.337072191336105\n",
      "Epoch: 141, loss: 19.280989019570868\n",
      "Epoch: 142, loss: 9.337072191336105\n",
      "Epoch: 143, loss: 19.1291702222306\n",
      "Epoch: 144, loss: 9.109338723254737\n",
      "Epoch: 145, loss: 18.294166836859134\n",
      "Epoch: 146, loss: 8.95751641120049\n",
      "Epoch: 147, loss: 18.137679593786036\n",
      "Epoch: 148, loss: 9.109338723254737\n",
      "Epoch: 149, loss: 18.218257438189\n",
      "Epoch: 150, loss: 8.95751641120049\n",
      "Epoch: 151, loss: 17.7628010461682\n",
      "Epoch: 152, loss: 8.881605255173369\n",
      "Epoch: 153, loss: 17.38325405281753\n",
      "Epoch: 154, loss: 8.653871787092001\n",
      "Epoch: 155, loss: 16.700069464786328\n",
      "Epoch: 156, loss: 8.426138319010633\n",
      "Epoch: 157, loss: 16.396431870105797\n",
      "Epoch: 158, loss: 8.35022716298351\n",
      "Epoch: 159, loss: 16.01688487675513\n",
      "Epoch: 160, loss: 7.894760226820772\n",
      "Epoch: 161, loss: 13.919669983362974\n",
      "Epoch: 162, loss: 7.059735753165432\n",
      "Epoch: 163, loss: 10.779139883229908\n",
      "Epoch: 164, loss: 5.769246100704345\n",
      "Epoch: 165, loss: 10.131001247079428\n",
      "Epoch: 166, loss: 5.389688563211741\n",
      "Epoch: 167, loss: 9.488687135265598\n",
      "Epoch: 168, loss: 5.161955095130373\n",
      "Epoch: 169, loss: 8.939134192564895\n",
      "Epoch: 170, loss: 4.934221627049005\n",
      "Epoch: 171, loss: 8.88141194590453\n",
      "Epoch: 172, loss: 4.934221627049005\n",
      "Epoch: 173, loss: 8.88141194590453\n",
      "Epoch: 174, loss: 4.858310471021882\n",
      "Epoch: 175, loss: 8.729594905921253\n",
      "Epoch: 176, loss: 4.706488158967637\n",
      "Epoch: 177, loss: 8.274138513900452\n",
      "Epoch: 178, loss: 4.630575245583524\n",
      "Epoch: 179, loss: 8.140209775862477\n",
      "Epoch: 180, loss: 4.554664089556401\n",
      "Epoch: 181, loss: 7.590953925869253\n",
      "Epoch: 182, loss: 4.175106552063797\n",
      "Epoch: 183, loss: 6.831866968595876\n",
      "Epoch: 184, loss: 3.4919026331057132\n",
      "Epoch: 185, loss: 6.072776496608522\n",
      "Epoch: 186, loss: 3.567803244990899\n",
      "Epoch: 187, loss: 5.541412463274578\n",
      "Epoch: 188, loss: 3.4255804524241698\n",
      "Epoch: 189, loss: 5.541412463274578\n",
      "Epoch: 190, loss: 3.4159791755796647\n",
      "Epoch: 191, loss: 5.314319028468926\n",
      "Epoch: 192, loss: 3.3400662621955526\n",
      "Epoch: 193, loss: 5.1618689846378905\n",
      "Epoch: 194, loss: 3.491885059535819\n",
      "Epoch: 195, loss: 5.237778383308023\n",
      "Epoch: 196, loss: 3.491885059535819\n",
      "Epoch: 197, loss: 5.237778383308023\n",
      "Epoch: 198, loss: 3.491885059535819\n",
      "Epoch: 199, loss: 5.237778383308023\n",
      "Epoch: 200, loss: 3.491885059535819\n",
      "Epoch: 201, loss: 5.237778383308023\n",
      "Epoch: 202, loss: 3.491885059535819\n",
      "Epoch: 203, loss: 5.237778383308023\n",
      "Epoch: 204, loss: 3.491885059535819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Aayush\\Codes\\Labs\\ML Lab\\Exp6-ann\\ANN.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 205, loss: 5.237778383308023\n",
      "Epoch: 206, loss: 3.491885059535819\n",
      "Epoch: 207, loss: 5.237778383308023\n",
      "Epoch: 208, loss: 3.491885059535819\n",
      "Epoch: 209, loss: 5.105836723007189\n",
      "Epoch: 210, loss: 3.491885059535819\n",
      "Epoch: 211, loss: 5.1618672272809\n",
      "Epoch: 212, loss: 3.4159756608656857\n",
      "Epoch: 213, loss: 5.1618672272809\n",
      "Epoch: 214, loss: 3.264156863525419\n",
      "Epoch: 215, loss: 5.010043157869665\n",
      "Epoch: 216, loss: 3.56780148763391\n",
      "Epoch: 217, loss: 5.1618619552099325\n",
      "Epoch: 218, loss: 3.4918920889637763\n",
      "Epoch: 219, loss: 5.085952556539798\n",
      "Epoch: 220, loss: 3.56780148763391\n",
      "Epoch: 221, loss: 5.085954313896788\n",
      "Epoch: 222, loss: 3.56780148763391\n",
      "Epoch: 223, loss: 5.3136807525502\n",
      "Epoch: 224, loss: 3.491893846320766\n",
      "Epoch: 225, loss: 5.465499549890466\n",
      "Epoch: 226, loss: 3.4918956036777553\n",
      "Epoch: 227, loss: 5.465499549890466\n",
      "Epoch: 228, loss: 3.416006812470479\n",
      "Epoch: 229, loss: 5.3895901512203315\n",
      "Epoch: 230, loss: 3.4159844476506325\n",
      "Epoch: 231, loss: 5.3895901512203315\n",
      "Epoch: 232, loss: 3.4159844476506325\n",
      "Epoch: 233, loss: 5.3895901512203315\n",
      "Epoch: 234, loss: 3.4159844476506325\n",
      "Epoch: 235, loss: 5.3895901512203315\n",
      "Epoch: 236, loss: 3.4159844476506325\n",
      "Epoch: 237, loss: 5.3895901512203315\n",
      "Epoch: 238, loss: 3.4159844476506325\n",
      "Epoch: 239, loss: 5.3895901512203315\n",
      "Epoch: 240, loss: 3.4159844476506325\n",
      "Epoch: 241, loss: 5.3895907587201\n",
      "Epoch: 242, loss: 3.4159844476506325\n",
      "Epoch: 243, loss: 5.454376179669222\n",
      "Epoch: 244, loss: 3.4159862050076217\n",
      "Epoch: 245, loss: 5.617318347230732\n",
      "Epoch: 246, loss: 3.4159862050076217\n",
      "Epoch: 247, loss: 5.467857272015674\n",
      "Epoch: 248, loss: 3.491900875748723\n",
      "Epoch: 249, loss: 5.845039513813174\n",
      "Epoch: 250, loss: 3.491906147819692\n",
      "Epoch: 251, loss: 5.617311317802774\n",
      "Epoch: 252, loss: 3.4919043904627025\n",
      "Epoch: 253, loss: 5.65599020953465\n",
      "Epoch: 254, loss: 3.491906147819692\n",
      "Epoch: 255, loss: 5.845039513813174\n",
      "Epoch: 256, loss: 3.491906147819692\n",
      "Epoch: 257, loss: 5.769130115143041\n",
      "Epoch: 258, loss: 3.491906147819692\n",
      "Epoch: 259, loss: 5.769130115143041\n",
      "Epoch: 260, loss: 3.491906147819692\n",
      "Epoch: 261, loss: 5.769130115143041\n",
      "Epoch: 262, loss: 3.5221904321054063\n",
      "Epoch: 263, loss: 6.072767709823575\n",
      "Epoch: 264, loss: 3.567817303846815\n",
      "Epoch: 265, loss: 5.541401919132641\n",
      "Epoch: 266, loss: 3.491904390462703\n",
      "Epoch: 267, loss: 5.541401919132641\n",
      "Epoch: 268, loss: 3.4159949917925694\n",
      "Epoch: 269, loss: 5.617311383910863\n",
      "Epoch: 270, loss: 3.4159949917925694\n",
      "Epoch: 271, loss: 5.541401919132641\n",
      "Epoch: 272, loss: 3.4159949917925694\n",
      "Epoch: 273, loss: 5.693220716472908\n",
      "Epoch: 274, loss: 3.567817303846815\n",
      "Epoch: 275, loss: 6.1486771084937075\n",
      "Epoch: 276, loss: 3.643728459873938\n",
      "Epoch: 277, loss: 5.69322098645006\n",
      "Epoch: 278, loss: 3.491906147819692\n",
      "Epoch: 279, loss: 5.6932455500286006\n",
      "Epoch: 280, loss: 3.491906147819692\n",
      "Epoch: 281, loss: 5.765041151664871\n",
      "Epoch: 282, loss: 3.567817303846815\n",
      "Epoch: 283, loss: 5.923241147878299\n",
      "Epoch: 284, loss: 3.643728459873938\n",
      "Epoch: 285, loss: 5.845039513813174\n",
      "Epoch: 286, loss: 3.567817303846815\n",
      "Epoch: 287, loss: 5.845039513813174\n",
      "Epoch: 288, loss: 3.567817303846815\n",
      "Epoch: 289, loss: 5.99685831115344\n",
      "Epoch: 290, loss: 3.643728459873938\n",
      "Epoch: 291, loss: 5.845039513813174\n",
      "Epoch: 292, loss: 3.491906147819692\n",
      "Epoch: 293, loss: 5.541401919132641\n",
      "Epoch: 294, loss: 3.491906147819692\n",
      "Epoch: 295, loss: 5.845039513813174\n",
      "Epoch: 296, loss: 3.491906147819692\n",
      "Epoch: 297, loss: 5.541401919132641\n",
      "Epoch: 298, loss: 3.491906147819692\n",
      "Epoch: 299, loss: 5.845039513813174\n",
      "Epoch: 300, loss: 3.567817303846815\n",
      "Epoch: 301, loss: 5.693220716472908\n",
      "Epoch: 302, loss: 3.491906147819692\n",
      "Epoch: 303, loss: 5.693220716472908\n",
      "Epoch: 304, loss: 3.491906147819692\n",
      "Epoch: 305, loss: 5.693220716472908\n",
      "Epoch: 306, loss: 3.5174842977965244\n",
      "Epoch: 307, loss: 5.769183287551277\n",
      "Epoch: 308, loss: 3.567817303846815\n",
      "Epoch: 309, loss: 5.769130115143041\n",
      "Epoch: 310, loss: 3.567817303846815\n",
      "Epoch: 311, loss: 5.7442189315588\n",
      "Epoch: 312, loss: 3.567817303846815\n",
      "Epoch: 313, loss: 5.694345969936899\n",
      "Epoch: 314, loss: 3.567817303846815\n",
      "Epoch: 315, loss: 5.880863993670252\n",
      "Epoch: 316, loss: 3.643730217230927\n",
      "Epoch: 317, loss: 5.99685831115344\n",
      "Epoch: 318, loss: 3.643730217230927\n",
      "Epoch: 319, loss: 6.072767709823575\n",
      "Epoch: 320, loss: 3.7196413732580496\n",
      "Epoch: 321, loss: 6.376405304504108\n",
      "Epoch: 322, loss: 3.871465442669285\n",
      "Epoch: 323, loss: 6.755948783140797\n",
      "Epoch: 324, loss: 4.326934136189011\n",
      "Epoch: 325, loss: 8.046408560533065\n",
      "Epoch: 326, loss: 5.1619568524873625\n",
      "Epoch: 327, loss: 9.640498903177905\n",
      "Epoch: 328, loss: 6.224713036867081\n",
      "Epoch: 329, loss: 11.386411557876993\n",
      "Epoch: 330, loss: 7.211559822576667\n",
      "Epoch: 331, loss: 13.96733111266153\n",
      "Epoch: 332, loss: 8.729782943119123\n",
      "Epoch: 333, loss: 18.066436883491743\n",
      "Epoch: 334, loss: 9.564805659417475\n",
      "Epoch: 335, loss: 18.673712072897608\n",
      "Epoch: 336, loss: 9.337072191336105\n",
      "Epoch: 337, loss: 18.521893275512543\n",
      "Epoch: 338, loss: 9.261161035308984\n",
      "Epoch: 339, loss: 18.066436883491743\n",
      "Epoch: 340, loss: 9.033427567227616\n",
      "Epoch: 341, loss: 17.76279928881121\n",
      "Epoch: 342, loss: 9.109338723254737\n",
      "Epoch: 343, loss: 17.76279928881121\n",
      "Epoch: 344, loss: 8.95751641120049\n",
      "Epoch: 345, loss: 17.405874316938192\n",
      "Epoch: 346, loss: 8.95751641120049\n",
      "Epoch: 347, loss: 17.003705302109875\n",
      "Epoch: 348, loss: 8.471286037175032\n",
      "Epoch: 349, loss: 15.713245524717607\n",
      "Epoch: 350, loss: 8.198404850929263\n",
      "Epoch: 351, loss: 14.270968707342064\n",
      "Epoch: 352, loss: 7.439293290658036\n",
      "Epoch: 353, loss: 12.045620765300793\n",
      "Epoch: 354, loss: 6.7560928864139305\n",
      "Epoch: 355, loss: 10.930955165856194\n",
      "Epoch: 356, loss: 6.224713036867081\n",
      "Epoch: 357, loss: 9.412772464524496\n",
      "Epoch: 358, loss: 5.237868008514485\n",
      "Epoch: 359, loss: 7.919054314302666\n",
      "Epoch: 360, loss: 4.402845292216134\n",
      "Epoch: 361, loss: 6.806773925872436\n",
      "Epoch: 362, loss: 3.871465442669285\n",
      "Epoch: 363, loss: 5.769130115143041\n",
      "Epoch: 364, loss: 3.4159932344355792\n",
      "Epoch: 365, loss: 5.237764324452107\n",
      "Epoch: 366, loss: 3.340080321051467\n",
      "Epoch: 367, loss: 4.85822084581542\n",
      "Epoch: 368, loss: 3.2641638929533765\n",
      "Epoch: 369, loss: 4.250949171168332\n",
      "Epoch: 370, loss: 3.1123363088281626\n",
      "Epoch: 371, loss: 3.871414479316591\n",
      "Epoch: 372, loss: 3.3400574754106045\n",
      "Epoch: 373, loss: 4.099137403256023\n",
      "Epoch: 374, loss: 3.112331036757194\n",
      "Epoch: 375, loss: 4.023235504822458\n",
      "Epoch: 376, loss: 3.1882386780703382\n",
      "Epoch: 377, loss: 4.0232280045858895\n",
      "Epoch: 378, loss: 3.112331036757194\n",
      "Epoch: 379, loss: 4.099140917970002\n",
      "Epoch: 380, loss: 3.0364198807300715\n",
      "Epoch: 381, loss: 4.099135645899033\n",
      "Epoch: 382, loss: 3.188242192784317\n",
      "Epoch: 383, loss: 3.871414479316591\n",
      "Epoch: 384, loss: 3.3400574754106045\n",
      "Epoch: 385, loss: 4.0232280045858895\n",
      "Epoch: 386, loss: 3.112331036757194\n",
      "Epoch: 387, loss: 3.9969539767982742\n",
      "Epoch: 388, loss: 3.112331036757194\n",
      "Epoch: 389, loss: 4.0232280045858895\n",
      "Epoch: 390, loss: 3.112331036757194\n",
      "Epoch: 391, loss: 3.947318643099259\n",
      "Epoch: 392, loss: 3.112331036757194\n",
      "Epoch: 393, loss: 4.023229761942879\n",
      "Epoch: 394, loss: 3.112331036757194\n",
      "Epoch: 395, loss: 3.9473168485587666\n",
      "Epoch: 396, loss: 3.188242192784317\n",
      "Epoch: 397, loss: 3.8714127219596017\n",
      "Epoch: 398, loss: 3.0364198807300715\n",
      "Epoch: 399, loss: 4.099132131185055\n",
      "Epoch: 400, loss: 3.03642515280104\n",
      "Epoch: 401, loss: 3.719593924619335\n",
      "Epoch: 402, loss: 3.1882386780703382\n",
      "Epoch: 403, loss: 4.175043287212177\n",
      "Epoch: 404, loss: 3.03642515280104\n",
      "Epoch: 405, loss: 3.719593924619335\n",
      "Epoch: 406, loss: 3.2641480767404714\n",
      "Epoch: 407, loss: 3.8714056925316442\n",
      "Epoch: 408, loss: 3.112332794114184\n",
      "Epoch: 409, loss: 3.795503323289468\n",
      "Epoch: 410, loss: 3.0364198807300715\n",
      "Epoch: 411, loss: 4.023219217800943\n",
      "Epoch: 412, loss: 3.0364269101580295\n",
      "Epoch: 413, loss: 3.795503323289468\n",
      "Epoch: 414, loss: 3.0364198807300715\n",
      "Epoch: 415, loss: 4.023219217800943\n",
      "Epoch: 416, loss: 3.0364269101580295\n",
      "Epoch: 417, loss: 3.7527371446159004\n",
      "Epoch: 418, loss: 3.0364198807300715\n",
      "Epoch: 419, loss: 4.083477014244549\n",
      "Epoch: 420, loss: 3.188249222212275\n",
      "Epoch: 421, loss: 3.6992258411321357\n",
      "Epoch: 422, loss: 3.112331036757194\n",
      "Epoch: 423, loss: 3.8714056925316442\n",
      "Epoch: 424, loss: 3.112332794114184\n",
      "Epoch: 425, loss: 3.643682768592212\n",
      "Epoch: 426, loss: 3.0364198807300715\n",
      "Epoch: 427, loss: 4.175043287212177\n",
      "Epoch: 428, loss: 2.9605157541309066\n",
      "Epoch: 429, loss: 3.5677698552080996\n",
      "Epoch: 430, loss: 3.188242192784317\n",
      "Epoch: 431, loss: 3.8714056925316442\n",
      "Epoch: 432, loss: 2.9605139967739174\n",
      "Epoch: 433, loss: 3.7954962938615107\n",
      "Epoch: 434, loss: 2.9605139967739174\n",
      "Epoch: 435, loss: 3.7954962938615107\n",
      "Epoch: 436, loss: 2.9605139967739174\n",
      "Epoch: 437, loss: 3.7954962938615107\n",
      "Epoch: 438, loss: 3.0364233954440505\n",
      "Epoch: 439, loss: 3.56776809785111\n",
      "Epoch: 440, loss: 3.188242192784317\n",
      "Epoch: 441, loss: 3.5677698552080996\n",
      "Epoch: 442, loss: 3.188242192784317\n",
      "Epoch: 443, loss: 3.7954962938615107\n",
      "Epoch: 444, loss: 3.0364233954440505\n",
      "Epoch: 445, loss: 3.56776809785111\n",
      "Epoch: 446, loss: 3.188242192784317\n",
      "Epoch: 447, loss: 3.5677698552080996\n",
      "Epoch: 448, loss: 3.188242192784317\n",
      "Epoch: 449, loss: 3.7205053191731197\n",
      "Epoch: 450, loss: 2.969900801325214\n",
      "Epoch: 451, loss: 4.023224489871911\n",
      "Epoch: 452, loss: 2.9605157541309066\n",
      "Epoch: 453, loss: 3.719586895191377\n",
      "Epoch: 454, loss: 3.0364233954440505\n",
      "Epoch: 455, loss: 3.56776809785111\n",
      "Epoch: 456, loss: 3.188242192784317\n",
      "Epoch: 457, loss: 3.5677698552080996\n",
      "Epoch: 458, loss: 3.188242192784317\n",
      "Epoch: 459, loss: 3.717794617047132\n",
      "Epoch: 460, loss: 3.0364233954440505\n",
      "Epoch: 461, loss: 3.56776809785111\n",
      "Epoch: 462, loss: 3.188242192784317\n",
      "Epoch: 463, loss: 3.5677698552080996\n",
      "Epoch: 464, loss: 3.188242192784317\n",
      "Epoch: 465, loss: 3.6440406645379917\n",
      "Epoch: 466, loss: 3.0364233954440505\n",
      "Epoch: 467, loss: 3.643677496521243\n",
      "Epoch: 468, loss: 3.0364233954440505\n",
      "Epoch: 469, loss: 3.643677496521243\n",
      "Epoch: 470, loss: 3.0364233954440505\n",
      "Epoch: 471, loss: 3.643677496521243\n",
      "Epoch: 472, loss: 3.0364233954440505\n",
      "Epoch: 473, loss: 3.643677496521243\n",
      "Epoch: 474, loss: 3.0364233954440505\n",
      "Epoch: 475, loss: 3.643677496521243\n",
      "Epoch: 476, loss: 3.0364233954440505\n",
      "Epoch: 477, loss: 3.643677496521243\n",
      "Epoch: 478, loss: 3.0364233954440505\n",
      "Epoch: 479, loss: 3.643677496521243\n",
      "Epoch: 480, loss: 3.0364233954440505\n",
      "Epoch: 481, loss: 3.643677496521243\n",
      "Epoch: 482, loss: 3.0364233954440505\n",
      "Epoch: 483, loss: 3.643677496521243\n",
      "Epoch: 484, loss: 3.0364233954440505\n",
      "Epoch: 485, loss: 3.643677496521243\n",
      "Epoch: 486, loss: 3.0364233954440505\n",
      "Epoch: 487, loss: 3.719586895191377\n",
      "Epoch: 488, loss: 2.9605157541309066\n",
      "Epoch: 489, loss: 4.250952685882311\n",
      "Epoch: 490, loss: 3.0364269101580295\n",
      "Epoch: 491, loss: 3.630042165267712\n",
      "Epoch: 492, loss: 3.112332794114184\n",
      "Epoch: 493, loss: 3.717661611148852\n",
      "Epoch: 494, loss: 2.9605157541309066\n",
      "Epoch: 495, loss: 4.175043287212177\n",
      "Epoch: 496, loss: 3.0364269101580295\n",
      "Epoch: 497, loss: 3.7195886525483663\n",
      "Epoch: 498, loss: 3.008008720110374\n",
      "Epoch: 499, loss: 4.175043287212177\n"
     ]
    }
   ],
   "source": [
    "mymodel = ANN()\n",
    "mymodel.fit(X_train, y_train, epochs=500, loss_threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87        34\n",
      "           1       0.93      0.97      0.95        80\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mymodel.predict(X_test)\n",
    "y_pred = [round(val) for val in y_pred]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be071fa3bb3c5273d3ad3c0c72285287e0b9b1ce4765e69a809d308e6cdbe2b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
